import scrapy
import re
from Tachie_get.items import *


class ForWhomTheGoldSpider(scrapy.Spider):
    name = 'for_whom_the_gold'
    allowed_domains = ['wiki.fwg.mobage.cn', 'static.mobage.cn']
    start_urls = ['http://wiki.fwg.mobage.cn/units?page_num=0']

    def parse(self, response):
        char_li = response.xpath('/html/body/div[2]/div/div[2]/div[1]/div/table/tbody/tr')
        for i in char_li:
            item = TachieGetItem()
            item['name'] = i.xpath('./td[1]/a/p/text()').extract_first()
            url = i.xpath('./td[1]/a/@href').extract_first()
            char_url = 'http://wiki.fwg.mobage.cn' + url
            # å‘é€è§’è‰²è¯¦æƒ…é¡µçš„è¯·æ±‚ï¼Œä½¿ç”¨å›è°ƒå‡½æ•°æ¥æ”¶å“åº”
            yield scrapy.Request(
                url=char_url,
                callback=self.get_tachie_url,
                meta={'item':item}  # ä½¿ç”¨metaåœ¨ä¸åŒå‡½æ•°ä¸­ä¼ é€’å‚æ•°
            )

        last_page = 13  # ç”±äºè¦çˆ¬å–ç½‘é¡µçš„ç‰¹æ®Šæ€§ï¼Œå³å€’æ•°ç¬¬äºŒé¡µä¸æœ€åä¸€é¡µçš„hrefå±æ€§å‡æŒ‡å‘æœ€åä¸€é¡µï¼Œæ‰€ä»¥é‡‡ç”¨äº†å¦ä¸€ç§æ–¹æ³•ï¼Œ13ä¸ºæœ€åä¸€é¡µçš„é¡µç 
        next_url = response.xpath(
            '/html/body/div[2]/div/div[2]/div[2]/a[3]/@href').extract_first()  # ä»â€œä¸‹ä¸€é¡µâ€buttonä¸­è·å–ä¸‹ä¸€é¡µçš„urlåœ°å€ï¼Œæ³¨æ„è‹¥ä¸ä½¿ç”¨extractfirst()æ–¹æ³•åˆ™è¿”å›å€¼ä¸ºä¸€ä¸ªåˆ—è¡¨
        now_page = response.xpath(
            '/html/body/div[2]/div/div[2]/div[2]/div[1]/a[@class="current"]/text()').extract_first()  # è·å–å½“å‰é¡µé¢çš„é¡µç 

        # åˆ¤æ–­æ˜¯å¦åˆ°è¾¾å°¾é¡µ
        if int(now_page) < last_page:
            next_url = 'http://wiki.fwg.mobage.cn/units' + next_url  # hrefå±æ€§å¹¶éå®Œæ•´çš„urlï¼Œéœ€è¦è¡¥å…¨åŸŸå
            # ä½¿ç”¨yieldå‘é€è¯·æ±‚
            yield scrapy.Request(
                url=next_url,  # è®¾ç½®ä¸‹ä¸€ä¸ªurl
                callback=self.parse  # è®¾ç½®å›è°ƒå‡½æ•°ä¸ºæœ¬èº«ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥å®šä¹‰ä¸€ä¸ªæ–°å‡½æ•°
            )


    # å¤„ç†è§’è‰²è¯¦æƒ…é¡µï¼Œè·å–è§’è‰²ç«‹ç»˜url
    def get_tachie_url(self, response):
        item = response.meta['item']
        url = response.xpath('/html/body/div[2]/div/div/div[1]/div[5]/div[1]/img/@src')
        item['img_url'] = url.extract_first()  # å°†ğŸ–¼å›¾ç‰‡urlåŠåç¼€ä¿å­˜è‡³item
        print(item['img_url'])
        item['img_class'] = url.extract_first().split('.')[-1]
        yield item

